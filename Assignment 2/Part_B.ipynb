{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part-B.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khdoin7c_Xwi"
      },
      "source": [
        "!pip install wandb\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZJvZS3UdTfb"
      },
      "source": [
        "# importing required packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import math\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Conv2D, Dense, MaxPooling2D, Flatten, Dropout, Activation, BatchNormalization, SpatialDropout2D\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import PIL\n",
        "import glob\n",
        "import zipfile\n",
        "import pathlib\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input as preprocess_input_InceptionResNetV2\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_input_ResNet50 \n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_input_InceptionV3\n",
        "from tensorflow.keras.applications.xception import preprocess_input as preprocess_input_Xception\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input as preprocess_input_Vgg19\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_input_Efficientnet_b3\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_input_Efficientnet_b7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyt0kEngFtyV"
      },
      "source": [
        "# data import\n",
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
        "data_dir = tf.keras.utils.get_file('/root/inature_12k.zip', origin=dataset_url, extract=False)\n",
        "\n",
        "import zipfile\n",
        "with zipfile.ZipFile(data_dir, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS4ZvRhJxJ1A"
      },
      "source": [
        "# checking import\n",
        "data_dir = '/content/inaturalist_12K'\n",
        "data_all =  data_dir + '/train'\n",
        "data_test = data_dir + '/val'\n",
        "\n",
        "data_path = pathlib.Path(data_dir)\n",
        "image_count = len(list(data_path.glob('*/*/*.jpg')))\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Uh24iSmI5k1"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "model_pixel_map = {\n",
        "    \"ResNet50\":224,\n",
        "    \"InceptionResNetV2\":299,\n",
        "    \"InceptionV3\":299,\n",
        "    \"Xception\":299,\n",
        "    \"Vgg19\":224,\n",
        "    \"Efficientnet_b3\": 300,\n",
        "    \"Efficientnet_b7\": 600,\n",
        "}\n",
        "\n",
        "def get_img_size(model_name):\n",
        "    return (model_pixel_map[model_name],model_pixel_map[model_name], 3)\n",
        "\n",
        "datagen_kwargs={\n",
        "    \"ResNet50\": dict(validation_split=.10, preprocessing_function=preprocess_input_ResNet50),\n",
        "    \"InceptionResNetV2\":dict(validation_split=.10, preprocessing_function=preprocess_input_InceptionResNetV2),\n",
        "    \"InceptionV3\": dict(validation_split=.10, preprocessing_function=preprocess_input_InceptionV3),\n",
        "    \"Xception\": dict(validation_split=.10, preprocessing_function=preprocess_input_Xception),\n",
        "    \"Vgg19\": dict(validation_split=.10, preprocessing_function=preprocess_input_Vgg19),\n",
        "    \"Efficientnet_b3\": dict(validation_split=.10, preprocessing_function=preprocess_input_Efficientnet_b3),\n",
        "    \"Efficientnet_b7\": dict(validation_split=.10, preprocessing_function=preprocess_input_Efficientnet_b7),\n",
        "}\n",
        "\n",
        "model_dict={\n",
        "    'ResNet50': tf.keras.applications.ResNet50, #weights=\"imagenet\",input_shape=get_img_size(ResNet50),include_top=False,\n",
        "    'Xception':keras.applications.Xception, #(weights=\"imagenet\",input_shape=get_img_size(Xception),include_top=False,),\n",
        "    'InceptionV3':keras.applications.InceptionV3, #(weights=\"imagenet\",input_shape=get_img_size(InceptionV3),include_top=False,),\n",
        "    'InceptionResNetV2':keras.applications.InceptionResNetV2, #(weights=\"imagenet\",input_shape=get_img_size(InceptionResNetV2),include_top=False,),\n",
        "    'Vgg19':keras.applications.VGG19, #(weights=\"imagenet\",input_shape=get_img_size(Vgg19),include_top=False,),\n",
        "    'Efficientnet_b3':tf.keras.applications.EfficientNetB3,\n",
        "    'Efficientnet_b7':tf.keras.applications.EfficientNetB7,\n",
        "}\n",
        "\n",
        "def get_base_model(model_name):\n",
        "  return model_dict[model_name](weights=\"imagenet\",input_shape=get_img_size(model_name),include_top=False,)\n",
        "\n",
        "def preproc(model_name):\n",
        "    img_size=(model_pixel_map[model_name],model_pixel_map[model_name])\n",
        "    datagen_kwarg=datagen_kwargs[model_name]\n",
        "    dataflow_kwarg=dict(target_size=img_size,batch_size=BATCH_SIZE)\n",
        "    return datagen_kwarg,dataflow_kwarg\n",
        "\n",
        "\n",
        "def transfer_learning(model_name,unfreeze_frac,do_data_augmentation,num_dense,train_num_epochs,finetune_num_epochs, callback=False, lr = 1e-6, dropout=0.2):\n",
        "    datagen_kwarg,dataflow_kwarg = preproc(model_name)\n",
        "\n",
        "    valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwarg)\n",
        "    val_ds = valid_datagen.flow_from_directory(data_all, subset=\"validation\", shuffle=False, **dataflow_kwarg)\n",
        "    if do_data_augmentation:\n",
        "        train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "            rotation_range=40,\n",
        "            horizontal_flip=True,\n",
        "            width_shift_range=0.2, height_shift_range=0.2,\n",
        "            shear_range=0.2, zoom_range=0.2,\n",
        "            **datagen_kwarg)\n",
        "    else:\n",
        "        train_datagen = valid_datagen\n",
        "    train_ds = train_datagen.flow_from_directory(data_all, subset=\"training\", shuffle=True, **dataflow_kwarg)\n",
        "\n",
        "    base_model = get_base_model(model_name)\n",
        "    base_model.trainable = False\n",
        "    inp = keras.Input(shape=(model_pixel_map[model_name], model_pixel_map[model_name], 3))\n",
        "\n",
        "    x=base_model(inp,training=False)\n",
        "    x=keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x=keras.layers.Dropout(dropout)(x)\n",
        "    x=keras.layers.Dense(num_dense,activation='relu')(x)\n",
        "    out=keras.layers.Dense(10, activation='softmax')(x)\n",
        "    model=keras.Model(inp,out)\n",
        "    model.compile(\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'],\n",
        "    )\n",
        "    if callback == True:\n",
        "        model.fit(train_ds,epochs=train_num_epochs,validation_data=val_ds, callbacks=[WandbCallback()])\n",
        "    else:\n",
        "        model.fit(train_ds,epochs=train_num_epochs,validation_data=val_ds)\n",
        "    \n",
        "    for layer in base_model.layers[-math.ceil((unfreeze_frac*(len(base_model.layers)))):]:\n",
        "      layer.trainable=True\n",
        "\n",
        "    model.compile(\n",
        "    optimizer=keras.optimizers.Adam(lr),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'],\n",
        "    )\n",
        "    if callback == True:\n",
        "        model.fit(train_ds,epochs=finetune_num_epochs,validation_data=val_ds, callbacks=[WandbCallback()])\n",
        "    else:\n",
        "        model.fit(train_ds,epochs=finetune_num_epochs,validation_data=val_ds)\n",
        "\n",
        "#transfer_learning('InceptionV3',0.25,False,128,2,2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhQS5h2hK9H9"
      },
      "source": [
        "# sweep config\n",
        "wandb.login()\n",
        "sweep_config = {\n",
        "    'method': 'random', #'bayes'\n",
        "    'metric': {\n",
        "        'name': 'val_loss',\n",
        "        'goal': 'minimise'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochpt': {\n",
        "            'values': [3,4]\n",
        "        },\n",
        "        'epochft': {\n",
        "            'values': [3,5,7]\n",
        "        },\n",
        "        'model': {\n",
        "            'values': [\"ResNet50\",\"InceptionResNetV2\", \"InceptionV3\", \"Xception\",\n",
        "                        \"Vgg19\",\"Efficientnet_b3\"]\n",
        "        },\n",
        "        'lr': {\n",
        "            'values': [1e-5, 1e-6]\n",
        "        },\n",
        "        'densel': {\n",
        "            'values': [128]\n",
        "        },\n",
        "        'finefrac': {\n",
        "            'values': [0.25, 0.5, 1.0]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0.2, 0.3]\n",
        "        },\n",
        "        'isDA': {\n",
        "            'values': [True, False]\n",
        "        }\n",
        "     }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"cs6910-a2\")\n",
        "# faec06b836487726bad6a3ad69f3dde4f473646c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdRctXkRK-PS"
      },
      "source": [
        "def wandb_train(config=None):\n",
        "    with wandb.init(config = config):\n",
        "        config = wandb.config\n",
        "        tf.keras.backend.clear_session()\n",
        "        transfer_learning(config.model, config.finefrac, config.isDA, config.densel, config.epochpt, config.epochft, True, config.lr, config.dropout)\n",
        "        runname = str(config.model)+'_ff.'+str(config.finefrac)+ '_epochs.'+str(config.epochpt) + '.'+str(config.epochft)\n",
        "        #runname += '_drop.'+str(config.dropout)+'_ds.'+str(config.denseN)\n",
        "        wandb.run.name = runname\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYgyvyx4l2vY"
      },
      "source": [
        "sweep_id = 'kk5ruac5'\n",
        "wandb.agent(sweep_id, wandb_train, count=15)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}